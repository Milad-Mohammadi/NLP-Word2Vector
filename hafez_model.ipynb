{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38FIWrODusU"
      },
      "source": [
        "# PreProcess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RJxdvrESCjDl"
      },
      "outputs": [],
      "source": [
        "#Read DataSet and Stop words\n",
        "\n",
        "with open (\"hafez.txt\", \"r\") as dataset:\n",
        "    data = dataset.read().splitlines()\n",
        "\n",
        "with open (\"fa_stop_words.txt\", \"r\") as fa_stop_words:\n",
        "    stop_words = fa_stop_words.read().splitlines()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rLf8MSKCFzS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62690884-853b-45e8-b88c-88a8f924aae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: \n",
            "1:  ﻿ \n",
            "2:  الا يا ايها الساقي ادر كاسا و ناولها \n",
            "3:  كه عشق آسان نمود اول ولي افتاد مشكل‌ها\n",
            "\n",
            "stop_words: \n",
            "1:  آباد \n",
            "2:  آخ \n",
            "3:  آخر\n"
          ]
        }
      ],
      "source": [
        "print(\"data:\", \"\\n1: \", data[0], \"\\n2: \", data[1], \"\\n3: \", data[2])\n",
        "print(\"\\nstop_words:\", \"\\n1: \", stop_words[18], \"\\n2: \", stop_words[19], \"\\n3: \", stop_words[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-H3zQowC4X9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_UPQvI83TmK"
      },
      "outputs": [],
      "source": [
        "!pip install hazm\n",
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "fZ0BK1EY53xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33f72a4-65d3-4742-d4a0-6a1ccaf0c5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized:  الا یا ایها الساقی ادر کاسا و ناولها\n",
            "Tokenized:  ['الا', 'یا', 'ایها', 'الساقی', 'ادر', 'کاسا', 'و', 'ناولها']\n",
            "Cleared:  ['ایها', 'الساقی', 'ادر', 'کاسا', 'ناولها']\n",
            "Sentence:  ایها الساقی ادر کاسا ناولها\n"
          ]
        }
      ],
      "source": [
        "normalizer = Normalizer()\n",
        "normalized_data = []\n",
        "tokenized_data = []\n",
        "clear_data = []\n",
        "clear_sentences = []\n",
        "\n",
        "\n",
        "for line in data:                              #### Normalize\n",
        "  if line and line != '\\ufeff':\n",
        "    normalized_data.append(normalizer.normalize(line))\n",
        "\n",
        "\n",
        "for line in normalized_data:                   #### Tokenize\n",
        "  tokenized_data.append(word_tokenize(line))\n",
        "\n",
        "\n",
        "for line in tokenized_data:                    #### Remove stop words\n",
        "  clear_line = []\n",
        "  for word in line:\n",
        "    if word not in stop_words:\n",
        "      clear_line.append(word)\n",
        "  clear_data.append(clear_line)\n",
        "\n",
        "\n",
        "\n",
        "for line in clear_data:                        #### Convert words to sentences\n",
        "  clear_sentences.append(\" \".join(line))\n",
        "\n",
        "clear_sentences = [item for item in clear_sentences if item]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Normalized: \", normalized_data[0])\n",
        "print(\"Tokenized: \", tokenized_data[0])\n",
        "print(\"Cleared: \", clear_data[0])\n",
        "print(\"Sentence: \", clear_sentences[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hafez_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}